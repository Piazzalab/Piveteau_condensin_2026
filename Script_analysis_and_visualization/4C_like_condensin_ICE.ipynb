{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates 4C-like contact profiles from a HiC matrix in cooler format binned at 1 kilobase. It requires a file listing the chromosomes and their length (S288c_chr_centro_coordinates.tsv provided with the reference genome file). It takes three main arguments:\n",
    "- the position of the viewpoint (DSB_pos, that will be translated into anchor_bin)\n",
    "- the size of the viewpoint to consider (the bin_size, on each side of the viewpoint)\n",
    "- the binning of the contacts to generate the 4C plot (the bin_size_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the packages and set the working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.5\n",
      "1.21.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "import pip\n",
    "import hicstuff as hcs\n",
    "import hicstuff.io as hio\n",
    "import hicstuff.view as hcv\n",
    "import hicstuff.digest as hcd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "todense = lambda x: hcv.sparse_to_dense(x, remove_diag=False)\n",
    "\n",
    "dir_seqs= \"/mnt/f/Nextcloud/Sequences/Genomes/\"\n",
    "input_dir = \"/mnt/e/Science/HiC/Contact_files/\"\n",
    "out_dir = \"/mnt/f/Nextcloud/DR07_UMR5239_Experiments/HiC/4C_analysis/Condensin_normalized/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for SCN normalized 4C-like at the RE on chr3 and 6 equivalent location in the genome relative to arm length and centro distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Function_RE(frags, mat, chrs, i, out_dir, max_mad, kernel_size, poly):\n",
    "    #kernel = np.ones(kernel_size)/kernel_size\n",
    "    VP_bin_size = 3000 #in bp\n",
    "    chrom = [\"chr3\", \"chr5\", \"chr8\", \"chr14\", \"chr2\", \"chr11\", \"chr13\"]\n",
    "    VP = [29000, 66000, 21000, 713000, 153000, 525631, 182646]\n",
    "    orientation = [\"F\", \"F\", \"F\", \"R\", \"F\", \"R\", \"F\"]\n",
    "\n",
    "    array_length = int(len(frags.loc[(frags[\"chrom\"]== chrom[0])]) - (VP[0]/1000))\n",
    "    \n",
    "    #set the main VP\n",
    "    main_VP_bin=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] >= VP[0]) & (frags[\"start_pos\"] < (VP[0]+VP_bin_size))].index.values)\n",
    "    \n",
    "    #define the stretch of data to look at for the main VP\n",
    "    if orientation[0] == \"F\":\n",
    "        main_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] >= VP[0])].index.values)\n",
    "    else:\n",
    "        main_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] <= VP[0])].index.values)\n",
    "        \n",
    "    distance_bp = len(main_VP_values)*1000\n",
    "    \n",
    "    main_VP_mat = mat[min(main_VP_bin):max(main_VP_bin),main_VP_values]\n",
    "    main_VP_mat = np.mean(main_VP_mat, axis=0)\n",
    "    main_VP_mat = main_VP_mat/sum(main_VP_mat)\n",
    "    final_mat = main_VP_mat\n",
    "    #final_mat_smooth = np.convolve(final_mat, kernel, mode='same')\n",
    "    final_mat_smooth = scipy.signal.savgol_filter(final_mat, kernel_size, poly)\n",
    "\n",
    "    for j in range(1, len(chrom),1):\n",
    "        ctl_VP_bin=np.array(frags.loc[(frags[\"chrom\"]== chrom[j]) & (frags[\"start_pos\"] >= VP[j]) & (frags[\"start_pos\"] < (VP[j]+VP_bin_size))].index.values)\n",
    "        #print(chrom[j])\n",
    "        #print(VP[j])\n",
    "        #print(orientation[j])\n",
    "        if orientation[j] == \"F\":\n",
    "            ctl_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[j]) & (frags[\"start_pos\"] >= VP[j]) & (frags[\"start_pos\"] < (VP[j]+distance_bp))].index.values)\n",
    "            ctl_VP_mat = mat[min(ctl_VP_bin):max(ctl_VP_bin),ctl_VP_values]\n",
    "            ctl_VP_mat = np.mean(ctl_VP_mat, axis=0)\n",
    "            ctl_VP_mat = ctl_VP_mat/sum(ctl_VP_mat)\n",
    "           \n",
    "            final_mat = np.column_stack((final_mat,ctl_VP_mat))\n",
    "        else:\n",
    "            ctl_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[j]) & (frags[\"start_pos\"] > (VP[j]-distance_bp)) & (frags[\"start_pos\"] <= VP[j])].index.values)\n",
    "            ctl_VP_mat = mat[min(ctl_VP_bin):max(ctl_VP_bin),ctl_VP_values]\n",
    "            ctl_VP_mat = np.mean(ctl_VP_mat, axis=0)\n",
    "            ctl_VP_mat = ctl_VP_mat/sum(ctl_VP_mat)  \n",
    "            \n",
    "            final_mat = np.column_stack((final_mat,np.flip(ctl_VP_mat)))\n",
    "    \n",
    "    #calculate the mean of the control values\n",
    "    ctl_average = np.mean(final_mat[:,1:len(VP)], axis=1)\n",
    "    #ctl_average_smooth = np.convolve(ctl_average, kernel, mode='same')\n",
    "    ctl_average_smooth = scipy.signal.savgol_filter(ctl_average, kernel_size, poly)\n",
    "    \n",
    "    #normalize the main VP values on the average of the control values\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        VP_normalized = np.true_divide(final_mat[:,0],ctl_average)\n",
    "        VP_normalized[VP_normalized == np.inf] = \"nan\"\n",
    "        VP_normalized_smooth = np.true_divide(final_mat_smooth,ctl_average_smooth)\n",
    "        VP_normalized_smooth[VP_normalized_smooth == np.inf] = \"nan\"\n",
    "        \n",
    "    #VP_normalized = np.nan_to_num(VP_normalized)\n",
    "    final_mat = np.column_stack((final_mat,ctl_average,VP_normalized,final_mat_smooth,ctl_average_smooth,VP_normalized_smooth))\n",
    "\n",
    "    final_mat = np.row_stack((np.append(chrom,[\"ctl_average\",\"VP_normalized\",\"VP_smooth\"+str(kernel_size),\"ctl_average_smooth\"+str(kernel_size),\"VP_normalized_smooth\"+str(kernel_size)]),\n",
    "                              np.append(VP,[\"NA\",\"NA\",\"NA\",\"NA\",\"NA\"]),\n",
    "                              np.append(orientation,[\"NA\",\"NA\",\"NA\",\"NA\",\"NA\"]),\n",
    "                              final_mat))\n",
    "    np.savetxt(out_dir + str(i) + \"_VP_\" + str(chrom[0])\n",
    "               + \"_\" + str(VP[0]) + \"_genome_bin1kb_Condensin_SCN\" + str(max_mad) + \"_smooth\"+ str(kernel_size) + \"_poly\" + str(poly) + \".tsv\", \n",
    "               final_mat, delimiter = \"\\t\", fmt='%s')\n",
    "    print(str(i) + \" RE function done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Function_rDNAleft(frags, mat, chrs, i, out_dir, max_mad, kernel_size, poly):\n",
    "    #kernel = np.ones(kernel_size)/kernel_size\n",
    "    VP_bin_size = 3000 #in bp\n",
    "    chrom = [\"chr12\", \"chr4\", \"chr14\", \"chr13\", \"chr15\", \"chr11\", \"chr2\"]\n",
    "    VP = [448000, 747000, 332000, 565000, 624000, 143000, 536000]\n",
    "    orientation = [\"R\", \"R\", \"F\", \"R\", \"R\", \"F\", \"R\"]\n",
    "\n",
    "    #determine the length onto which contacts will be normalized. It is given by the main VP and will be applied to control VPs.\n",
    "    array_length = int(len(frags.loc[(frags[\"chrom\"]== chrom[0])]) - (VP[0]/1000))\n",
    "        \n",
    "    #set the main VP\n",
    "    main_VP_bin=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] >= VP[0]) & (frags[\"start_pos\"] < (VP[0]+VP_bin_size))].index.values)\n",
    "    \n",
    "    #define the stretch of data to look at for the main VP\n",
    "    if orientation[0] == \"F\":\n",
    "        main_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] >= VP[0])].index.values)\n",
    "        main_VP_mat = mat[min(main_VP_bin):max(main_VP_bin),main_VP_values]\n",
    "        main_VP_mat = np.mean(main_VP_mat, axis=0)\n",
    "        main_VP_mat = main_VP_mat/sum(main_VP_mat)\n",
    "        final_mat = main_VP_mat\n",
    "        #final_mat_smooth = np.convolve(final_mat, kernel, mode='same')\n",
    "        final_mat_smooth = scipy.signal.savgol_filter(final_mat, kernel_size, poly)\n",
    "        \n",
    "    else:\n",
    "        main_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] <= (VP[0]-VP_bin_size))].index.values)\n",
    "        main_VP_mat = mat[min(main_VP_bin):max(main_VP_bin),main_VP_values]\n",
    "        main_VP_mat = np.mean(main_VP_mat, axis=0)\n",
    "        main_VP_mat = main_VP_mat/sum(main_VP_mat)\n",
    "        final_mat = np.flip(main_VP_mat)\n",
    "        #final_mat_smooth = np.convolve(final_mat, kernel, mode='same')\n",
    "        final_mat_smooth = scipy.signal.savgol_filter(final_mat, kernel_size, poly)\n",
    "        \n",
    "    distance_bp = len(main_VP_values)*1000\n",
    "    \n",
    "    for j in range(1, len(chrom),1):\n",
    "        ctl_VP_bin=np.array(frags.loc[(frags[\"chrom\"]== chrom[j]) & (frags[\"start_pos\"] >= VP[j]) & (frags[\"start_pos\"] < (VP[j]+VP_bin_size))].index.values)\n",
    "        #print(chrom[j])\n",
    "        #print(VP[j])\n",
    "        #print(orientation[j])\n",
    "        if orientation[j] == \"F\":\n",
    "            ctl_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[j]) & (frags[\"start_pos\"] >= VP[j]) & (frags[\"start_pos\"] < (VP[j]+distance_bp))].index.values)\n",
    "            ctl_VP_mat = mat[min(ctl_VP_bin):max(ctl_VP_bin),ctl_VP_values]\n",
    "            ctl_VP_mat = np.mean(ctl_VP_mat, axis=0)\n",
    "            ctl_VP_mat = ctl_VP_mat/sum(ctl_VP_mat)  \n",
    "           \n",
    "            final_mat = np.column_stack((final_mat,ctl_VP_mat))\n",
    "        else:\n",
    "            ctl_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[j]) & (frags[\"start_pos\"] > (VP[j]-distance_bp)) & (frags[\"start_pos\"] <= VP[j])].index.values)\n",
    "            ctl_VP_mat = mat[min(ctl_VP_bin):max(ctl_VP_bin),ctl_VP_values]\n",
    "            ctl_VP_mat = np.mean(ctl_VP_mat, axis=0)\n",
    "            ctl_VP_mat = ctl_VP_mat/sum(ctl_VP_mat)  \n",
    "            \n",
    "            final_mat = np.column_stack((final_mat,np.flip(ctl_VP_mat)))\n",
    "    \n",
    "    #calculate the mean of the control values\n",
    "    ctl_average = np.mean(final_mat[:,1:len(VP)], axis=1)\n",
    "    #ctl_average_smooth = np.convolve(ctl_average, kernel, mode='same')\n",
    "    ctl_average_smooth = scipy.signal.savgol_filter(ctl_average, kernel_size, poly)\n",
    "    \n",
    "    #normalize the main VP values on the average of the control values\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        VP_normalized = np.true_divide(final_mat[:,0],ctl_average)\n",
    "        VP_normalized[VP_normalized == np.inf] = \"nan\"\n",
    "        VP_normalized_smooth = np.true_divide(final_mat_smooth,ctl_average_smooth)\n",
    "        VP_normalized_smooth[VP_normalized_smooth == np.inf] = \"nan\"\n",
    "    #VP_normalized = np.nan_to_num(VP_normalized)\n",
    "    final_mat = np.column_stack((final_mat,ctl_average,VP_normalized,final_mat_smooth,ctl_average_smooth,VP_normalized_smooth))\n",
    "\n",
    "    final_mat = np.row_stack((np.append(chrom,[\"ctl_average\",\"VP_normalized\",\"VP_smooth\"+str(kernel_size),\"ctl_average_smooth\"+str(kernel_size),\"VP_normalized_smooth\"+str(kernel_size)]),\n",
    "                              np.append(VP,[\"NA\",\"NA\",\"NA\",\"NA\",\"NA\"]),\n",
    "                              np.append(orientation,[\"NA\",\"NA\",\"NA\",\"NA\",\"NA\"]),\n",
    "                              final_mat))\n",
    "    np.savetxt(out_dir + str(i) + \"_VP_\" + str(chrom[0])\n",
    "               + \"_\" + str(VP[0]) + \"_rDNA_flankleft448-451_bin1kb_Condensin_SCN\" + str(max_mad) + \"_smooth\"+ str(kernel_size) + \"_poly\" + str(poly) + \".tsv\", \n",
    "               final_mat, delimiter = \"\\t\", fmt='%s')    \n",
    "    print(str(i) + \" rDNAleft function done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Function_RE_chr4_fwd(frags, mat, chrs, i, out_dir, max_mad, kernel_size):\n",
    "    kernel = np.ones(kernel_size)/kernel_size\n",
    "    VP_bin_size = 4000 #in bp\n",
    "    chrom = [\"chr4\"]\n",
    "    VP = [678000]\n",
    "    orientation = [\"F\"]\n",
    "\n",
    "    #determine the length onto which contacts will be normalized. It is given by the main VP and will be applied to control VPs.\n",
    "    array_length = int(len(frags.loc[(frags[\"chrom\"]== chrom[0])]) - (VP[0]/1000))   \n",
    "   \n",
    "    #set the main VP\n",
    "    main_VP_bin=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] >= VP[0]) & (frags[\"start_pos\"] < (VP[0]+VP_bin_size))].index.values)\n",
    "    \n",
    "    #define the stretch of data to look at for the main VP\n",
    "    if orientation[0] == \"F\":\n",
    "        main_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] >= VP[0]+VP_bin_size)].index.values)\n",
    "        main_VP_mat = mat[min(main_VP_bin):max(main_VP_bin),main_VP_values]\n",
    "        main_VP_mat = np.mean(main_VP_mat, axis=0)\n",
    "        main_VP_mat = main_VP_mat/sum(main_VP_mat)\n",
    "        final_mat = main_VP_mat\n",
    "        final_mat_smooth = scipy.signal.savgol_filter(final_mat, kernel_size, 1)\n",
    "    else:\n",
    "        main_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] <= (VP[0]))].index.values)\n",
    "        main_VP_mat = mat[min(main_VP_bin):max(main_VP_bin),main_VP_values]\n",
    "        main_VP_mat = np.mean(main_VP_mat, axis=0)\n",
    "        main_VP_mat = main_VP_mat/sum(main_VP_mat)\n",
    "        final_mat = np.flip(main_VP_mat)\n",
    "        final_mat_smooth = scipy.signal.savgol_filter(final_mat, kernel_size, 1)\n",
    "\n",
    "    final_mat = np.column_stack((final_mat,final_mat_smooth))\n",
    "    final_mat = np.row_stack((np.append(chrom,[\"VP_smooth\"+str(kernel_size)]),\n",
    "                              np.append(VP,[\"NA\"]),\n",
    "                              np.append(orientation,[\"NA\"]),\n",
    "                              final_mat))\n",
    "    np.savetxt(out_dir + str(i) + \"_VP_\" + str(chrom[0])\n",
    "               + \"_\" + str(VP[0]) + \"_RE_chr4_678000_FWD_VP4kb_bin1kb_Condensin_SCN\" + str(max_mad) + \"_smooth\" +\n",
    "               str(kernel_size) + \"_poly_\" + str(poly) +\".tsv\", \n",
    "               final_mat, delimiter = \"\\t\", fmt='%s')    \n",
    "    print(str(i) + \" RE_chr4 FWD function done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Function_RE_chr4_rev(frags, mat, chrs, i, out_dir, max_mad, kernel_size):\n",
    "    kernel = np.ones(kernel_size)/kernel_size\n",
    "    VP_bin_size = 4000 #in bp\n",
    "    chrom = [\"chr4\"]\n",
    "    VP = [678000]\n",
    "    orientation = [\"R\"]\n",
    "\n",
    "    #determine the length onto which contacts will be normalized. It is given by the main VP and will be applied to control VPs.\n",
    "    array_length = int(len(frags.loc[(frags[\"chrom\"]== chrom[0])]) - (VP[0]/1000))   \n",
    "   \n",
    "    #set the main VP\n",
    "    main_VP_bin=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] >= VP[0]) & (frags[\"start_pos\"] < (VP[0]+VP_bin_size))].index.values)\n",
    "    \n",
    "    #define the stretch of data to look at for the main VP\n",
    "    if orientation[0] == \"F\":\n",
    "        main_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] >= VP[0]+VP_bin_size)].index.values)\n",
    "        main_VP_mat = mat[min(main_VP_bin):max(main_VP_bin),main_VP_values]\n",
    "        main_VP_mat = np.mean(main_VP_mat, axis=0)\n",
    "        main_VP_mat = main_VP_mat/sum(main_VP_mat)\n",
    "        final_mat = main_VP_mat\n",
    "        final_mat_smooth = scipy.signal.savgol_filter(final_mat, kernel_size, 1)\n",
    "    else:\n",
    "        main_VP_values=np.array(frags.loc[(frags[\"chrom\"]== chrom[0]) & (frags[\"start_pos\"] <= (VP[0]))].index.values)\n",
    "        main_VP_mat = mat[min(main_VP_bin):max(main_VP_bin),main_VP_values]\n",
    "        main_VP_mat = np.mean(main_VP_mat, axis=0)\n",
    "        main_VP_mat = main_VP_mat/sum(main_VP_mat)\n",
    "        final_mat = np.flip(main_VP_mat)\n",
    "        final_mat_smooth = scipy.signal.savgol_filter(final_mat, kernel_size, 1)\n",
    "\n",
    "    final_mat = np.column_stack((final_mat,final_mat_smooth))\n",
    "    final_mat = np.row_stack((np.append(chrom,[\"VP_smooth\"+str(kernel_size)]),\n",
    "                              np.append(VP,[\"NA\"]),\n",
    "                              np.append(orientation,[\"NA\"]),\n",
    "                              final_mat))\n",
    "    np.savetxt(out_dir + str(i) + \"_VP_\" + str(chrom[0])\n",
    "               + \"_\" + str(VP[0]) + \"_RE_chr4_678000_REV_VP4kb_bin1kb_Condensin_SCN\" + str(max_mad) + \"_smooth\"+ str(kernel_size) +\n",
    "               \"_poly_\" + str(poly) + \".tsv\", \n",
    "               final_mat, delimiter = \"\\t\", fmt='%s')    \n",
    "    print(str(i) + \" RE_chr4 REV function done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=[\"AP57_S288c_DSB_chr3_rDNA_normal_q20_v312\",\n",
    "\"AP103_S288c_DSB_chr3_rDNA_normal_q20_v312\",\n",
    "\"AD24_S288c_DSB_chr3_rDNA_cutsite_q20\",\n",
    "\"AD161_S288c_DSB_chr3_rDNA_cutsite_q20\",\n",
    "\"AD392-400_merged_S288c_DSB_chr3_rDNA_cutsite_q20\"]\n",
    "sample=[\"AD392-400_merged_S288c_DSB_chr3_rDNA_cutsite_q20\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the smoothing parameters \"kernel_size\" and \"poly\" and run the 4C functions. \n",
    "An input cooler file or a graal file together with the fragment list generated by hicstuff can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD392-400_merged_S288c_DSB_chr3_rDNA_cutsite_q20 starts\n",
      "AD392-400_merged_S288c_DSB_chr3_rDNA_cutsite_q20 rDNAleft function done\n",
      "AD392-400_merged_S288c_DSB_chr3_rDNA_cutsite_q20 RE function done\n",
      "AD392-400_merged_S288c_DSB_chr3_rDNA_cutsite_q20 RE_chr4 FWD function done\n",
      "AD392-400_merged_S288c_DSB_chr3_rDNA_cutsite_q20 RE_chr4 REV function done\n",
      "AD392-400_merged_S288c_DSB_chr3_rDNA_cutsite_q20 done\n"
     ]
    }
   ],
   "source": [
    "chrs = pd.read_csv(str(dir_seqs + \"Yeast_genome_S288c_R64-2-1_2014/S288c_chr_centro_coordinates.tsv\"), sep = \"\\t\")\n",
    "max_mad=3\n",
    "kernel_size=39\n",
    "poly=2\n",
    "#kernel_size=3\n",
    "#poly=1\n",
    "#kernel_size=41 #if using savgol filter of scipy\n",
    "for i in sample:\n",
    "    print(str(i) + \" starts\")\n",
    "    #Load a fragment file, that gives the correspondance between chromosome and position and the row/column in the dense matrix. \n",
    "    #This fragment file is generated by hicstuff using the rebin function. It is generated as part of the master hicstuff script #Script_hicstuff_arima.sh\n",
    "    \n",
    "    #frags = pd.read_csv(str(input_dir + \"Rebin/S288c/\" + str(i) + \"_1kb.frags.tsv\"), sep = \"\\t\")\n",
    "    #sparse_mat = hio.load_sparse_matrix(str(input_dir + \"Rebin/S288c/\" + str(i) +  \"_1kb.mat.tsv\"))\n",
    "        \n",
    "    sparse_mat, frags, chrs = hio.flexible_hic_loader(str(input_dir + \"Cool/S288c/\" + str(i) +  \"_1kb.cool\"))\n",
    "    #sparse_mat, frags, chrs = hio.flexible_hic_loader(str(input_dir + \"Cool/S288c/\" + str(i) +  \"1000_balanced.cool\")) #if coming from PSMN\n",
    "    \n",
    "    sparse_mat_SCN = hcs.normalize_sparse(sparse_mat, norm='ICE', iterations=40, n_mad=max_mad)   \n",
    "    #mat = hcv.sparse_to_dense(sparse_mat_SCN)\n",
    "    \n",
    "\n",
    "    Function_rDNAleft(frags, mat, chrs, i, out_dir, max_mad, kernel_size, poly)\n",
    "    Function_RE(frags, mat, chrs, i, out_dir, max_mad, kernel_size, poly)\n",
    "    Function_RE_chr4_fwd(frags, mat, chrs, i, out_dir, max_mad, kernel_size)\n",
    "    Function_RE_chr4_rev(frags, mat, chrs, i, out_dir, max_mad, kernel_size)\n",
    "    print(str(i) + \" done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
